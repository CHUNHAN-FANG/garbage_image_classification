{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像样本集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from keras.utils import np_utils, to_categorical\n",
    "import os\n",
    "import glob\n",
    "from imutils import paths   #基于opencv的比较好用的工具箱\n",
    "import imutils\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from PIL import Image, ImageFile, ImageEnhance\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 文件路径加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file structure...\n",
      "['F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C0paper_recycle\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C1paper_gan\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C2paperpacking\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C3plastic\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C4plastic_bottle\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C5plastic_product\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C6plastic_packing\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C7metal\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C8glass\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\C9tile\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\CAfabric\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\CBwood\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\CCdust\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\CDwet\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\CEfood_waste\\\\', 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\CFfood_packaging\\\\']\n"
     ]
    }
   ],
   "source": [
    "fileDir='F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\' #图像样本文件路径\n",
    "total_images = 0\n",
    "major = os.listdir(fileDir)  \n",
    "full_path = []\n",
    "print(\"Loading file structure...\")\n",
    "for a in major:\n",
    "      full_path.append(fileDir + a + \"\\\\\") \n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 检查当前目录下损坏的图片文件并删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "# just for unit test\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    badFilesList = []\n",
    "    for i in full_path:\n",
    "        curDir = i\n",
    "        for root, dirs, files in os.walk(curDir):\n",
    "            # print(files)\n",
    "            # 检查当前目录中的损坏的图片文件\n",
    "            for each in files:\n",
    "                # for each in os.listdir('./'):\n",
    "                if each.endswith('.png') or each.endswith('.jpg') or each.endswith('.gif') or each.endswith(\n",
    "                        '.JPG') or each.endswith('.PNG') or each.endswith('.GIF') or each.endswith(\n",
    "                    '.jpeg') or each.endswith(\n",
    "                    '.JPEG'):\n",
    "                    # print(each)\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        im = Image.open(os.path.join(root, each))\n",
    "                        # im.show()\n",
    "                    except Exception as e:\n",
    "                        print('Bad file:', os.path.join(root, each))\n",
    "                        badFilesList.append(os.path.join(root, each))\n",
    "\n",
    "        # 删除损坏的文件\n",
    "        if len(badFilesList) != 0:\n",
    "            for each in badFilesList:\n",
    "                try:\n",
    "                    os.remove(each)\n",
    "                except Exception as e:\n",
    "                    print('Del file: %s failed, %s' % (each, e))\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据集处理方法一"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 数据增强 均衡数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#旋转\n",
    "def rotation(root_path, img_name):\n",
    "    img = Image.open(os.path.join(root_path, img_name))\n",
    "    if img.mode == \"P\" or 'RGBA':\n",
    "        img = img.convert('RGB')    \n",
    "    rotation_img = img.rotate(20) #旋转角度\n",
    "    # rotation_img.save(os.path.join(root_path,img_name.split('.')[0] + '_rotation.jpg'))\n",
    "    return rotation_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#翻转\n",
    "def flip(root_path,img_name):   #翻转图像\n",
    "    \n",
    "    img = Image.open(os.path.join(root_path, img_name))\n",
    "    if img.mode == \"P\" or 'RGBA':\n",
    "        img = img.convert('RGB')    \n",
    "    filp_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    # filp_img.save(os.path.join(root_path,img_name.split('.')[0] + '_flip.jpg'))\n",
    "    return filp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 针对不同分类图像文件夹，选用数据增强方式执行，如尘土类（15）图片较少，可选用旋转方式增强样本，纸巾干垃圾图集较多，可不增强，实现样本均衡\n",
    "# 旋转\n",
    "for lable in range(15,16):\n",
    "    #print(full_path[lable])\n",
    "    imageDir = full_path[lable]\n",
    "    saveDir = full_path[lable]\n",
    "    i=0\n",
    "    for name in os.listdir(imageDir):\n",
    "        i=i+1\n",
    "        saveName=\"xz\"+str(i)+\".jpg\"\n",
    "        saveImage=rotation(imageDir,name)\n",
    "        saveImage.save(os.path.join(saveDir,saveName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#翻转\n",
    "for lable in range(1,2):\n",
    "    #print(full_path[lable])\n",
    "    imageDir = full_path[lable]\n",
    "    saveDir = full_path[lable]\n",
    "    i=0        \n",
    "    for name in os.listdir(imageDir):\n",
    "            i=i+1\n",
    "            saveName=\"fz\"+str(i)+\".jpg\"\n",
    "            saveImage=flip(imageDir,name)\n",
    "            saveImage.save(os.path.join(saveDir,saveName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增加及随机采样，实现样本均衡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 图像预处理 及 划分测试集训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images...\n",
      "label: C0paper_recycle : 0\n",
      "The total number of images in trainingC\\C0paper_recycle\\ = 1768\n",
      "label: C1paper_gan : 1\n",
      "The total number of images in trainingC\\C1paper_gan\\ = 2147\n",
      "label: C2paperpacking : 2\n",
      "The total number of images in trainingC\\C2paperpacking\\ = 1614\n",
      "label: C3plastic : 3\n",
      "The total number of images in trainingC\\C3plastic\\ = 2173\n",
      "label: C4plastic_bottle : 4\n",
      "The total number of images in trainingC\\C4plastic_bottle\\ = 1704\n",
      "label: C5plastic_product : 5\n",
      "The total number of images in trainingC\\C5plastic_product\\ = 2284\n",
      "label: C6plastic_packing : 6\n",
      "The total number of images in trainingC\\C6plastic_packing\\ = 2221\n",
      "label: C7metal : 7\n",
      "The total number of images in trainingC\\C7metal\\ = 1908\n",
      "label: C8glass : 8\n",
      "The total number of images in trainingC\\C8glass\\ = 2143\n",
      "label: C9tile : 9\n",
      "The total number of images in trainingC\\C9tile\\ = 2038\n",
      "label: CAfabric : 10\n",
      "The total number of images in trainingC\\CAfabric\\ = 2108\n",
      "label: CBwood : 11\n",
      "The total number of images in trainingC\\CBwood\\ = 2047\n",
      "label: CCdust : 12\n",
      "The total number of images in trainingC\\CCdust\\ = 1640\n",
      "label: CDwet : 13\n",
      "The total number of images in trainingC\\CDwet\\ = 1945\n",
      "label: CEfood_waste : 14\n",
      "The total number of images in trainingC\\CEfood_waste\\ = 2022\n",
      "label: CFfood_packaging : 15\n",
      "The total number of images in trainingC\\CFfood_packaging\\ = 1669\n",
      "The total number of images in data = 31431\n"
     ]
    }
   ],
   "source": [
    "RESOLUTION=192     ##分辨率大小设置\n",
    "#将图片数字化       \n",
    "print(\"Loading training images...\")\n",
    "X_train = []\n",
    "for i in full_path:\n",
    "    images_in_folder = 0\n",
    "    label = i.split('\\\\')[1]    \n",
    "    #label = label.split('-')[0]    一级分类\n",
    "    labelIndex=all_labels.index(label)  ##读取标签索引\n",
    "    print('label:',label,':',labelIndex)\n",
    "    for file in glob.glob(i + \"*.jpg\"):\n",
    "        try:\n",
    "            img = cv.cvtColor(cv.imread(file),cv.COLOR_BGR2RGB)   ## 颜色空间转化\n",
    "                                ##cv.imread(file)读取图像为数据  \n",
    "                                ##cv.COLOR_BGR2RGB 转颜色通道\n",
    "        except:\n",
    "            Exception\n",
    "            continue\n",
    "        img = cv.resize(img, (RESOLUTION,RESOLUTION))  ##分辨率大小192*192统一尺寸  #由于电脑性能限制，没有提高分辨率训练，一般建议224及以上\n",
    "        total_images+=1\n",
    "        X_train.append(img)\n",
    "        y_labels.append(labelIndex) ##同时读取标签\n",
    "        images_in_folder += 1\n",
    "    print(\"The total number of images in %s = %d\" % (i,images_in_folder))\n",
    "print(\"The total number of images in data = \" + str(total_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    " #查看有几类标签\n",
    "print(np.unique(y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多分类编码转为onehot编码\n",
    "y_labels = to_categorical(y_labels)  ##onehot编码可以结合1 文件的10，11块输出部分理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正则化\n",
    "#图片数据规范化，数据归一化，会减少损失函数的震荡，有助于减小损失函数提高精度。\n",
    "X_train = np.array(X_train, np.float32) / 255.\n",
    "# Normalization标准化处理、标准差\n",
    "X_norm = (X_train - X_train.mean(axis=0))/X_train.std(axis = 0)\n",
    "# 洗牌 打乱数据\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_labels = shuffle(X_norm, y_labels,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据保存成功！\n"
     ]
    }
   ],
   "source": [
    "# #保存处理好的数据与标签\n",
    "# np.save('encoded/X_train.npy',X_train)\n",
    "# np.save('encoded/y_labels.npy',y_labels)\n",
    "# print(\"数据保存成功！\")\n",
    "# ## 运行成功后自动生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 拆分训练集测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(X_train, y_labels, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据保存成功！\n"
     ]
    }
   ],
   "source": [
    "#保存处理好的数据与标签\n",
    "np.save('encoded/X_train_C_192.npy', Xtrain)\n",
    "np.save('encoded/X_valid_C_192.npy', Xvalid)\n",
    "np.save('encoded/Y_train_C_192.npy', Ytrain)\n",
    "np.save('encoded/Y_valid_C_192.npy', Yvalid)\n",
    "print(\"数据保存成功！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本实验后续使用以上（方法一）处理后的数据集，进行自定义CNN实验及DenseNet迁移学习实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下文的方法二是另一种处理处理方式摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据集处理方法二"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 划分训练集/测试集 图像文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "finishedfile:C0paper_recycle\n",
      "2\n",
      "finishedfile:C1paper_gan\n",
      "3\n",
      "finishedfile:C2paperpacking\n",
      "4\n",
      "finishedfile:C3plastic\n",
      "5\n",
      "finishedfile:C4plastic_bottle\n",
      "6\n",
      "finishedfile:C5plastic_product\n",
      "7\n",
      "finishedfile:C6plastic_packing\n",
      "8\n",
      "finishedfile:C7metal\n",
      "9\n",
      "finishedfile:C8glass\n",
      "10\n",
      "finishedfile:C9tile\n",
      "11\n",
      "finishedfile:CAfabric\n",
      "12\n",
      "finishedfile:CBwood\n",
      "13\n",
      "finishedfile:CCdust\n",
      "14\n",
      "finishedfile:CDwet\n",
      "15\n",
      "finishedfile:CEfood_waste\n",
      "16\n",
      "finishedfile:CFfood_packaging\n"
     ]
    }
   ],
   "source": [
    "import random, shutil\n",
    "def moveFile(fileDir):\n",
    "        pathDir = os.listdir(fileDir)    #取图片的原始路径\n",
    "        filenumber=len(pathDir)\n",
    "        rate=0.3    #自定义抽取图片的比例\n",
    "        picknumber=int(filenumber*rate) #按照rate比例从文件夹中取一定数量图片\n",
    "        sample = random.sample(pathDir, picknumber)  #随机选取picknumber数量的样本图片\n",
    "        #print (sample)\n",
    "        for name in sample:\n",
    "                shutil.move(fileDir+name, tarDir+name)  #将文件或目录(源)递归移动到另一个位置(目标)并返回目标。\n",
    "        return\n",
    "\n",
    "label_L = []\n",
    "for i in full_path:\n",
    "    label = i.split('\\\\')[5] #从路径中提取文件夹标签\n",
    "    label_L.append(label)\n",
    "    fileDir = i\n",
    "    tarDir = 'F:\\\\ipython\\\\Computer_Vision\\\\GC\\\\trainingC\\\\validation\\\\'+label+'\\\\' # 目标（测试集）文件路径\n",
    "    moveFile(fileDir)\n",
    "    print('finishedfile:'+label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，已完成各子类别文件夹划分训练/测试集；由于子类别文件夹已经按照不同类别完成整理，因此直接按文件夹作为图片样本的标签，用来生成数据集。\n",
    "\n",
    "后面部分将使用ImageDataGenerator.flow_from_directory(directory)方法来生成数据集，因此先构建训练/验证数据集的文件路径名："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    " \n",
    "import tensorflow as tf\n",
    " \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(fileDir, 'train')\n",
    "validation_dir = os.path.join(fileDir, 'validation')\n",
    "\n",
    "# 各类样本分布统计\n",
    "num_total_train, num_total_val=0,0\n",
    "for i in range len(label_L):\n",
    "    train_dir_i = os.path.join(train_dir, label_L[i])  \n",
    "    validation_dir_i = os.path.join(validation_dir, label_L[i])  \n",
    "    num_tr_i = len(os.listdir(train_dir_i))\n",
    "    num_val_i = len(os.listdir(validation_dir_i))\n",
    "    print(label_L[i]+' training images:\\t',train_dir_i,'\\t validation images:\\t',validation_dir_i,'\\n')\n",
    "    num_total_train += num_tr_i\n",
    "    num_total_val += num_val_i\n",
    "print('Total training images:\\t',num_total_train,'\\t validation images:\\t',num_total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_from_directory(directory): 以文件夹路径为参数,生成经过数据提升/归一化后的数据,在一个无限循环中无限产生batch数据\n",
    "    \n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之后直接以train_data_gen等作为数据集放进fit里训练即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
